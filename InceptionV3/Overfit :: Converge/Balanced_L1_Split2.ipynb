{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34283 images belonging to 15 classes.\n",
      "Found 8564 images belonging to 15 classes.\n",
      "total Atelectasis images:        2015\n",
      "total Cardiomegaly images:       464\n",
      "total Consolidation images:      633\n",
      "total Edema images:              310\n",
      "total Effusion images:           1804\n",
      "total Emphysema images:          461\n",
      "total Fibrosis images:           366\n",
      "total Hernia images:             53\n",
      "total Infiltration images:       4640\n",
      "total Mass images:               1043\n",
      "total No_Finding images:         28000\n",
      "total Nodule images:             1273\n",
      "total Pleural_Thickening images: 525\n",
      "total Pneumonia images:          161\n",
      "total Pneumothorax images:       1099\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer dense_7 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.core.Dense'>. Full input: [<keras.layers.core.Dense object at 0x7f1fc50e69b0>]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    473\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 474\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'keras.layers.core.Dense'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d4da8b89bad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m# and a logistic layer -- let..'s say we have 200 classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m# this is the model we will train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer dense_7 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.core.Dense'>. Full input: [<keras.layers.core.Dense object at 0x7f1fc50e69b0>]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "base_dir = '/media/ente/M2/2018 - 11 - sorted data'\n",
    "class_names = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax' ]\n",
    "export_dir= '/home/ente/Dropbox/THESIS/Code/Transfer_InceptionV3/Export'\n",
    "\n",
    "#preprocessing\n",
    "validation_split = 0.2\n",
    "input_size = 299\n",
    "target_size = (input_size,input_size)\n",
    "color_mode='rgb'\n",
    "color_channels = 3\n",
    "#color_mode='grayscale'\n",
    "\n",
    "#layers + optimizer\n",
    "dropout=0.3\n",
    "batch_size = 32\n",
    "epochs1 = 10\n",
    "epochs2 = 35\n",
    "dense_units=1024\n",
    "class_mode = 'categorical'\n",
    "import keras_metrics\n",
    "metrics= ['categorical_accuracy', keras_metrics.precision(), keras_metrics.recall()]\n",
    "\n",
    "#class dirs\n",
    "import os\n",
    "ate_dir = os.path.join(base_dir, class_names[0])\n",
    "car_dir = os.path.join(base_dir, class_names[1])\n",
    "con_dir = os.path.join(base_dir, class_names[2])\n",
    "ede_dir = os.path.join(base_dir, class_names[3])\n",
    "eff_dir = os.path.join(base_dir, class_names[4])\n",
    "emp_dir = os.path.join(base_dir, class_names[5])\n",
    "fib_dir = os.path.join(base_dir, class_names[6])\n",
    "her_dir = os.path.join(base_dir, class_names[7])\n",
    "inf_dir = os.path.join(base_dir, class_names[8])\n",
    "mas_dir = os.path.join(base_dir, class_names[9])\n",
    "nof_dir = os.path.join(base_dir, class_names[10])\n",
    "nod_dir = os.path.join(base_dir, class_names[11])\n",
    "ple_dir = os.path.join(base_dir, class_names[12])\n",
    "pne_dir = os.path.join(base_dir, class_names[13])\n",
    "pn2_dir = os.path.join(base_dir, class_names[14])\n",
    "#filenames\n",
    "ate_fnames = os.listdir(ate_dir)\n",
    "car_fnames = os.listdir(car_dir)\n",
    "con_fnames = os.listdir(con_dir)\n",
    "ede_fnames = os.listdir(ede_dir)\n",
    "eff_fnames = os.listdir(eff_dir)\n",
    "emp_fnames = os.listdir(emp_dir)\n",
    "fib_fnames = os.listdir(fib_dir)\n",
    "her_fnames = os.listdir(her_dir)\n",
    "inf_fnames = os.listdir(inf_dir)\n",
    "mas_fnames = os.listdir(mas_dir)\n",
    "nof_fnames = os.listdir(nof_dir)\n",
    "nod_fnames = os.listdir(nod_dir)\n",
    "ple_fnames = os.listdir(ple_dir)\n",
    "pne_fnames = os.listdir(pne_dir)\n",
    "pn2_fnames = os.listdir(pn2_dir)\n",
    "#print (train_ate_fnames[:10])\n",
    "#train_car_fnames.sort()\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    validation_split=validation_split) # set validation split\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode,\n",
    "    color_mode=color_mode, \n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    base_dir, # same directory as training data\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode, #Determines the type of label arrays that are returned:\"categorical\" will be 2D one-hot encoded labels,\n",
    "    color_mode=color_mode, \n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "print ('total Atelectasis images:       ', len(os.listdir(ate_dir))) \n",
    "print ('total Cardiomegaly images:      ', len(os.listdir(car_dir))) \n",
    "print ('total Consolidation images:     ', len(os.listdir(con_dir))) \n",
    "print ('total Edema images:             ', len(os.listdir(ede_dir))) \n",
    "print ('total Effusion images:          ', len(os.listdir(eff_dir))) \n",
    "print ('total Emphysema images:         ', len(os.listdir(emp_dir))) \n",
    "print ('total Fibrosis images:          ', len(os.listdir(fib_dir))) \n",
    "print ('total Hernia images:            ', len(os.listdir(her_dir))) \n",
    "print ('total Infiltration images:      ', len(os.listdir(inf_dir))) \n",
    "print ('total Mass images:              ', len(os.listdir(mas_dir))) \n",
    "print ('total No_Finding images:        ', len(os.listdir(nof_dir))) \n",
    "print ('total Nodule images:            ', len(os.listdir(nod_dir))) \n",
    "print ('total Pleural_Thickening images:', len(os.listdir(ple_dir))) \n",
    "print ('total Pneumonia images:         ', len(os.listdir(pne_dir))) \n",
    "print ('total Pneumothorax images:      ', len(os.listdir(pn2_dir))) \n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = (input_size, input_size, color_channels))\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(dense_units, activation='relu')(x)\n",
    "#x = Dropout(dropout)(x)\n",
    "x= Dense(512, input_dim=dense_units, kernel_regularizer=regularizers.l2(0.01))\n",
    "# and a logistic layer -- let..'s say we have 200 classes\n",
    "predictions = Dense(len(class_names), activation = 'softmax') (x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=metrics)\n",
    "model.summary()\n",
    "# train the model on the new data for a few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1=model.fit_generator(    \n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    class_weight = 'balanced',\n",
    "    epochs = epochs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FtxcKjJfxL9"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(history1.history['categorical_accuracy'])\n",
    "pyplot.plot(history1.history['val_categorical_accuracy'])\n",
    "pyplot.title('Training and validation accuracy')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history1.history['loss'])\n",
    "pyplot.plot(history1.history['val_loss'])\n",
    "pyplot.title('Training and validation loss')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = model.predict_generator(validation_generator, validation_generator.samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_ANwJCnx7w-"
   },
   "source": [
    "## Export Model + Weights\n",
    "\n",
    "#Run the following cell to export results to disk\n",
    "import h5py\n",
    "model.save_weights(export_dir + 'my_model_weights#2.h5')\n",
    "\n",
    "#save as JSON\n",
    "json_string = model.to_json()\n",
    "\n",
    "#save as YAML\n",
    "yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2=model.fit_generator(    \n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    class_weight = 'balanced',\n",
    "    epochs = epochs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = model.predict_generator(validation_generator, validation_generator.samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FtxcKjJfxL9"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(history2.history['categorical_accuracy'])\n",
    "pyplot.plot(history2.history['val_categorical_accuracy'])\n",
    "pyplot.title('Training and validation accuracy')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history2.history['loss'])\n",
    "pyplot.plot(history2.history['val_loss'])\n",
    "pyplot.title('Training and validation loss')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "visualization_model = Model(base_model.input, successive_outputs)\n",
    "\n",
    "# Let's prepare a random input image of a cat or dog from the training set.\n",
    "cat_img_files = [os.path.join(ate_dir, f) for f in ate_fnames]\n",
    "dog_img_files = [os.path.join(car_dir, f) for f in car_fnames]\n",
    "img_path = random.choice(cat_img_files + dog_img_files)\n",
    "\n",
    "img = load_img(img_path, target_size=target_size)  # this is a PIL image\n",
    "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# Rescale by 1/255\n",
    "x /= 255\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "  if len(feature_map.shape) == 4:\n",
    "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = feature_map.shape[1]\n",
    "    # We will tile our images in this matrix\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    for i in range(n_features):\n",
    "      # Postprocess the feature to make it visually palatable\n",
    "      x = feature_map[0, :, :, i]\n",
    "      x -= x.mean()\n",
    "      x /= x.std()\n",
    "      x *= 64\n",
    "      x += 128\n",
    "      x = np.clip(x, 0, 255).astype('uint8')\n",
    "      # We'll tile each filter into this big horizontal grid\n",
    "      display_grid[:, i * size : (i + 1) * size] = x\n",
    "    # Display the grid\n",
    "    scale = 20. / n_features\n",
    "    pyplot.figure(figsize=(scale * n_features, scale))\n",
    "    pyplot.title(layer_name)\n",
    "    pyplot.grid(False)\n",
    "    pyplot.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a list of accuracy results on training and test data\n",
    "# sets for each training epoch\n",
    "acc = history2.history['categorical_accuracy']\n",
    "val_acc = history2.history['val_categorical_accuracy']\n",
    "\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "\n",
    "print(acc)\n",
    "print(val_acc)\n",
    "print(loss)\n",
    "print(val_loss)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "jTEzoMx6CasV"
   ],
   "name": "image_classification_part3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
