{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "intTransformedLabels = encoder.fit_transform(labels)\n",
    "print(intTransformedLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "values = array(labels)\n",
    "print(labels)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_dir = '/media/ente/M2/2018 - 11 - sorted data'\n",
    "labels = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax' ]\n",
    "#class dirs\n",
    "import os\n",
    "ate_dir = os.path.join(base_dir, labels[0])\n",
    "car_dir = os.path.join(base_dir, labels[1])\n",
    "con_dir = os.path.join(base_dir, labels[2])\n",
    "ede_dir = os.path.join(base_dir, labels[3])\n",
    "eff_dir = os.path.join(base_dir, labels[4])\n",
    "emp_dir = os.path.join(base_dir, labels[5])\n",
    "fib_dir = os.path.join(base_dir, labels[6])\n",
    "her_dir = os.path.join(base_dir, labels[7])\n",
    "inf_dir = os.path.join(base_dir, labels[8])\n",
    "mas_dir = os.path.join(base_dir, labels[9])\n",
    "nof_dir = os.path.join(base_dir, labels[10])\n",
    "nod_dir = os.path.join(base_dir, labels[11])\n",
    "ple_dir = os.path.join(base_dir, labels[12])\n",
    "pne_dir = os.path.join(base_dir, labels[13])\n",
    "pn2_dir = os.path.join(base_dir, labels[14])\n",
    "#filenames\n",
    "ate_fnames = os.listdir(ate_dir)\n",
    "car_fnames = os.listdir(car_dir)\n",
    "con_fnames = os.listdir(con_dir)\n",
    "ede_fnames = os.listdir(ede_dir)\n",
    "eff_fnames = os.listdir(eff_dir)\n",
    "emp_fnames = os.listdir(emp_dir)\n",
    "fib_fnames = os.listdir(fib_dir)\n",
    "her_fnames = os.listdir(her_dir)\n",
    "inf_fnames = os.listdir(inf_dir)\n",
    "mas_fnames = os.listdir(mas_dir)\n",
    "nof_fnames = os.listdir(nof_dir)\n",
    "nod_fnames = os.listdir(nod_dir)\n",
    "ple_fnames = os.listdir(ple_dir)\n",
    "pne_fnames = os.listdir(pne_dir)\n",
    "pn2_fnames = os.listdir(pn2_dir)\n",
    "\n",
    "print ('total Atelectasis images:       ', len(os.listdir(ate_dir))) \n",
    "print ('total Cardiomegaly images:      ', len(os.listdir(car_dir))) \n",
    "print ('total Consolidation images:     ', len(os.listdir(con_dir))) \n",
    "print ('total Edema images:             ', len(os.listdir(ede_dir))) \n",
    "print ('total Effusion images:          ', len(os.listdir(eff_dir))) \n",
    "print ('total Emphysema images:         ', len(os.listdir(emp_dir))) \n",
    "print ('total Fibrosis images:          ', len(os.listdir(fib_dir))) \n",
    "print ('total Hernia images:            ', len(os.listdir(her_dir))) \n",
    "print ('total Infiltration images:      ', len(os.listdir(inf_dir))) \n",
    "print ('total Mass images:              ', len(os.listdir(mas_dir))) \n",
    "print ('total No_Finding images:        ', len(os.listdir(nof_dir))) \n",
    "print ('total Nodule images:            ', len(os.listdir(nod_dir))) \n",
    "print ('total Pleural_Thickening images:', len(os.listdir(ple_dir))) \n",
    "print ('total Pneumonia images:         ', len(os.listdir(pne_dir))) \n",
    "print ('total Pneumothorax images:      ', len(os.listdir(pn2_dir))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split + Preprocessing + Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "rescale = 224\n",
    "target_size = (rescale, rescale)\n",
    "input_shape = (rescale, rescale, 3)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #rescale=((1./255)-.5)*2,\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    validation_split=0.2) # set validation split\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb', \n",
    "    #classes=intTransformedLabels,\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    base_dir, # same directory as training data\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    #early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto'),\n",
    "    class_mode='categorical', #Determines the type of label arrays that are returned:\"categorical\" will be 2D one-hot encoded labels,\n",
    "    color_mode='rgb',\n",
    "    #classes=intTransformedLabels,\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "print(validation_generator.class_indices)\n",
    "print(validation_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 15)                15375     \n",
      "=================================================================\n",
      "Total params: 40,421,199\n",
      "Trainable params: 0\n",
      "Non-trainable params: 40,421,199\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "import keras_metrics as km\n",
    "\n",
    "#layers + optimizer\n",
    "#metrics= ['categorical_accuracy', km.precision(), km.recall()]\n",
    "# build the VGG16 network\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape = (224,224,3))\n",
    "model =  Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())#model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "model.add(Dense(15, activation = 'softmax'))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block) to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer and a very slow learning rate.\n",
    "model.compile(loss='categorical_crossentropy',optimizer=SGD(lr=1e-4, momentum=0.9),metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Teil#1 (Pre-Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1=model.fit_generator(    \n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    class_weight = 'balanced',\n",
    "    epochs = epochs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bewertung des Pre-Trainings\n",
    "### 1) Lernkurve betrachten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FtxcKjJfxL9"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(history1.history['categorical_accuracy'])\n",
    "pyplot.plot(history1.history['val_categorical_accuracy'])\n",
    "pyplot.title('Training and validation accuracy')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history1.history['loss'])\n",
    "pyplot.plot(history1.history['val_loss'])\n",
    "pyplot.title('Training and validation loss')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Wahrheitsmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = model.predict_generator(validation_generator, validation_generator.samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_ANwJCnx7w-"
   },
   "source": [
    "## Export Model + Weights\n",
    "\n",
    "Run the following cell to export results to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hUmyohAyBzh"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "export_dir= '/home/ente/Dropbox/THESIS/Code/Transfer_InceptionV3/Export'\n",
    "model.save_weights(export_dir + 'my_model_weights#2.h5')\n",
    "\n",
    "#### save as JSON\n",
    "json_string = model.to_json()\n",
    "\n",
    "#### save as YAML\n",
    "yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tt15y6IS2pBo"
   },
   "source": [
    "## Fine-Tuning\n",
    "### Schichten auftauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the first convolution blocks, i.e. we will freeze\n",
    "# the first 24 layers and unfreeze the rest:\n",
    "for layer in model.layers[:15]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[15:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Teil#2 (Fine-Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "#metrics= ['categorical_accuracy']\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE37ARlqY9da"
   },
   "source": [
    "Now let's retrain the model. We'll train on all images available, for 50 epochs, and validate on all test images. (This will take 2-3 hours to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "history2=model.fit_generator(    \n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    class_weight = 'balanced',\n",
    "    epochs = epochs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bewertung des Fine-Tunings\n",
    "### 1) Lernkurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FtxcKjJfxL9"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(history2.history['categorical_accuracy'])\n",
    "pyplot.plot(history2.history['val_categorical_accuracy'])\n",
    "pyplot.title('Training and validation accuracy')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history2.history['loss'])\n",
    "pyplot.plot(history2.history['val_loss'])\n",
    "pyplot.title('Training and validation loss')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Wahrheitsmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = model.predict_generator(validation_generator, validation_generator.samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Schichten visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "visualization_model = Model(base_model.input, successive_outputs)\n",
    "\n",
    "# Let's prepare a random input image of a cat or dog from the training set.\n",
    "cat_img_files = [os.path.join(ate_dir, f) for f in ate_fnames]\n",
    "dog_img_files = [os.path.join(car_dir, f) for f in car_fnames]\n",
    "img_path = random.choice(cat_img_files + dog_img_files)\n",
    "\n",
    "img = load_img(img_path, target_size=target_size)  # this is a PIL image\n",
    "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# Rescale by 1/255\n",
    "x /= 255\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "  if len(feature_map.shape) == 4:\n",
    "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = feature_map.shape[1]\n",
    "    # We will tile our images in this matrix\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    for i in range(n_features):\n",
    "      # Postprocess the feature to make it visually palatable\n",
    "      x = feature_map[0, :, :, i]\n",
    "      x -= x.mean()\n",
    "      x /= x.std()\n",
    "      x *= 64\n",
    "      x += 128\n",
    "      x = np.clip(x, 0, 255).astype('uint8')\n",
    "      # We'll tile each filter into this big horizontal grid\n",
    "      display_grid[:, i * size : (i + 1) * size] = x\n",
    "    # Display the grid\n",
    "    scale = 20. / n_features\n",
    "    pyplot.figure(figsize=(scale * n_features, scale))\n",
    "    pyplot.title(layer_name)\n",
    "    pyplot.grid(False)\n",
    "    pyplot.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a list of accuracy results on training and test data\n",
    "# sets for each training epoch\n",
    "acc = history1.history['categorical_accuracy']\n",
    "val_acc = history1.history['val_categorical_accuracy']\n",
    "\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "loss = history1.history['loss']\n",
    "val_loss = history1.history['val_loss']\n",
    "\n",
    "print(acc)\n",
    "print(val_acc)\n",
    "print(loss)\n",
    "print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a list of accuracy results on training and test data\n",
    "# sets for each training epoch\n",
    "acc = history2.history['categorical_accuracy']\n",
    "val_acc = history2.history['val_categorical_accuracy']\n",
    "\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "\n",
    "print(acc)\n",
    "print(val_acc)\n",
    "print(loss)\n",
    "print(val_loss)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "jTEzoMx6CasV"
   ],
   "name": "image_classification_part3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
